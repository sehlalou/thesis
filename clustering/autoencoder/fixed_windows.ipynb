{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_HOME=/usr/lib/cuda  # Replace with your actual CUDA path\n",
      "env: CUDA_PATH=/usr/lib/cuda\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_HOME=/usr/lib/cuda  # Replace with your actual CUDA path\n",
    "%env CUDA_PATH=/usr/lib/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load PyTorch/1.12.1-foss-2022a-CUDA-11.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDS_FOLDER = \"/mnt/iridia/sehlalou/thesis/ECGs\"\n",
    "SAMPLING_RATE = 200\n",
    "WINDOW_SIZE = 8192  # Nombre de points par segment ECG\n",
    "STEP_SIZE = 4096    # Chevauchement de 50%\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation du signal ECG en fenêtre de taille fixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_signal(signal, window_size, step_size):\n",
    "    segments = []\n",
    "    for i in range(0, len(signal) - window_size, step_size):\n",
    "        segments.append(signal[i : i + window_size])\n",
    "    return np.array(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage passe-bande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(signal, lowcut=0.5, highcut=50, fs=200, order=2):\n",
    "    nyquist = 0.5 * fs\n",
    "    low, high = lowcut / nyquist, highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement en mémoire des records (à la volée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(records_folder):\n",
    "    record_files = sorted(glob.glob(os.path.join(records_folder, \"*.h5\")))\n",
    "    for record_file in record_files:\n",
    "        with h5py.File(record_file, \"r\") as f:\n",
    "            ecg_data = f[\"ecg\"][:]  # Load ECG data\n",
    "            raw_ecg_lead1 = ecg_data[6000:, 0]\n",
    "            filtered_ecg_lead1 = bandpass_filter(raw_ecg_lead1)\n",
    "\n",
    "            # Calcul du bruit supprimé\n",
    "            noise_removed = raw_ecg_lead1 - filtered_ecg_lead1\n",
    "            segments = segment_signal(filtered_ecg_lead1, WINDOW_SIZE, STEP_SIZE)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "                \n",
    "            plt.subplot(3, 1, 1)\n",
    "            plt.plot(raw_ecg_lead1, color='gray', alpha=0.7, label=\"ECG brut (avec bruit)\")\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(3, 1, 2)\n",
    "            plt.plot(filtered_ecg_lead1, color='blue', label=\"ECG filtré\")\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(3, 1, 3)\n",
    "            plt.plot(noise_removed, color='red', label=\"Bruit supprimé\")\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.xlabel(\"Temps (échantillons)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            for seg in segments:\n",
    "                seg = np.expand_dims(seg, axis=-1)  # Add a dimension for CNN\n",
    "                seg = seg.astype(np.float32)\n",
    "                yield seg, seg  # Yield (input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(RECORDS_FOLDER),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=((WINDOW_SIZE, 1), (WINDOW_SIZE, 1))\n",
    ")\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (WINDOW_SIZE, 1)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = layers.MaxPooling1D(2, padding=\"same\")(x)\n",
    "x = layers.Conv1D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling1D(2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded = layers.Dense(10, activation=\"relu\")(x)  # Espace latent\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(encoded)\n",
    "x = layers.Reshape((64, 1))(x)\n",
    "x = layers.Conv1DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.UpSampling1D(2)(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.UpSampling1D(2)(x)\n",
    "decoded = layers.Conv1D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(dataset, epochs= EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoded').output)\n",
    "latent_features = encoder.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2 \n",
    "\n",
    "# Initialize and fit K-Means\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(latent_features)\n",
    "\n",
    "# Retrieve cluster labels\n",
    "cluster_labels = kmeans.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
